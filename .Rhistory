# using hyperparameters
rf_tuning <- setHyperPars(rf, par.vals = rf_tune$x)
# configurando os parâmetros de tuning
rf <- mlr::train(rf_tuning, train_task)
getLearnerModel(rf)
# passando o conjunto de teste para o modelo
predict_rf<-predict(rf, test_task)
predict_rf
df <- data.frame(predict_rf$data)
# definindo a classe positiva como 1 (com diabetes)
# avaliar os resultados
library(caret)
confusionMatrix(df$response, df$truth, positive = levels(df$truth)[2])
# avaliando onde o modelo está errando
# df_error <- df[df$truth != df$response, ]
# df_error
#
# # selecionar as instâncias que o modelo errou
# data_select_error <- data_select[df_error$id,]
# data_select_error
beep()
roc.curve(df$truth, df$response, plotit = F)
getParamSet("classif.randomForest")
source('~/GitHub/predict_diabetes_diagnostic/test_model.R', encoding = 'UTF-8')
# teste local do modelo
# Etapa de criação do modelo
rm(list=ls())
# carga dos dados transformados
load("data/features_selection.RData")
head(data_select)
# library(ROSE)
# #
# # método de over e undersampling
# balanced_target <- ovun.sample(classe ~ ., data = data_select, method = "both",N = 680, seed = 1)$data
# data_select <- balanced_target
library(beepr)
library(mlr)
# tamanho dos dados para treino
size_sample <-  floor(0.7 * nrow(data_select))
set.seed(123)
# particionamento aleatório
train_ind <- sample(seq_len(nrow(data_select)), size_sample)
# training x test
data_train <- data_select[train_ind, ]
data_test <- data_select[-train_ind, ]
# criando as tasks
train_task <- makeClassifTask(data = data_train, target = "classe")
test_task <- makeClassifTask(data = data_test, target = "classe")
# # normalizando as variáveis
train_task <- normalizeFeatures(train_task, method = "standardize" )
test_task <- normalizeFeatures(test_task, method = "standardize")
# removendo features
# train_task <- dropFeatures(task = train_task,features = c("grossura_pele"))
rf <- makeLearner("classif.randomForest", predict.type = "prob", par.vals = list(mtry = 3, ntree = 200, importance = TRUE, oob.prox = TRUE))
getParamSet("classif.randomForest")
# gridsearch (parametros de tuning)
parameters <- makeParamSet(
makeIntegerParam("ntree",lower = 50, upper = 500),
makeIntegerParam("mtry", lower = 2, upper = 8),
makeIntegerParam("nodesize", lower = 5, upper = 50)
)
control_tune <- makeTuneControlRandom(maxit = 100L)
# cv
cv <- makeResampleDesc("CV",iters = 10L)
rf_tune <- tuneParams(learner = rf, resampling = cv, task = train_task, par.set = parameters, control = control_tune, show.info = TRUE)
# teste local do modelo
# Etapa de criação do modelo
rm(list=ls())
# carga dos dados transformados
load("data/features_selection.RData")
head(data_select)
# library(ROSE)
# #
# # método de over e undersampling
# balanced_target <- ovun.sample(classe ~ ., data = data_select, method = "both",N = 680, seed = 1)$data
# data_select <- balanced_target
library(beepr)
library(mlr)
# tamanho dos dados para treino
size_sample <-  floor(0.7 * nrow(data_select))
set.seed(123)
# particionamento aleatório
train_ind <- sample(seq_len(nrow(data_select)), size_sample)
# training x test
data_train <- data_select[train_ind, ]
data_test <- data_select[-train_ind, ]
# criando as tasks
train_task <- makeClassifTask(data = data_train, target = "classe")
test_task <- makeClassifTask(data = data_test, target = "classe")
# # normalizando as variáveis
train_task <- normalizeFeatures(train_task, method = "standardize" )
test_task <- normalizeFeatures(test_task, method = "standardize")
# removendo features
# train_task <- dropFeatures(task = train_task,features = c("grossura_pele"))
rf <- makeLearner("classif.randomForest", predict.type = "prob", par.vals = list(mtry = 3, ntree = 200, importance = TRUE, oob.prox = TRUE))
getParamSet("classif.randomForest")
# gridsearch (parametros de tuning)
parameters <- makeParamSet(
makeIntegerParam("ntree",lower = 50, upper = 500),
makeIntegerParam("mtry", lower = 2, upper = 8),
makeIntegerParam("nodesize", lower = 5, upper = 50)
)
control_tune <- makeTuneControlRandom(maxit = 100L)
# cv
cv <- makeResampleDesc("CV",iters = 10L)
rf_tune <- tuneParams(learner = rf, resampling = cv, task = train_task, par.set = parameters, control = control_tune, show.info = TRUE)
# using hyperparameters
rf_tuning <- setHyperPars(rf, par.vals = rf_tune$x)
# configurando os parâmetros de tuning
rf <- mlr::train(rf_tuning, train_task)
getLearnerModel(rf)
# passando o conjunto de teste para o modelo
predict_rf<-predict(rf, test_task)
predict_rf
df <- data.frame(predict_rf$data)
# definindo a classe positiva como 1 (com diabetes)
# avaliar os resultados
library(caret)
confusionMatrix(df$response, df$truth, positive = levels(df$truth)[2])
# avaliando onde o modelo está errando
# df_error <- df[df$truth != df$response, ]
# df_error
#
# # selecionar as instâncias que o modelo errou
# data_select_error <- data_select[df_error$id,]
# data_select_error
beep()
roc.curve(df$truth, df$response, plotit = F)
# teste local do modelo
# Etapa de criação do modelo
rm(list=ls())
# carga dos dados transformados
load("data/features_selection.RData")
head(data_select)
# library(ROSE)
# #
# # método de over e undersampling
# balanced_target <- ovun.sample(classe ~ ., data = data_select, method = "both",N = 680, seed = 1)$data
# data_select <- balanced_target
library(beepr)
library(mlr)
# tamanho dos dados para treino
size_sample <-  floor(0.7 * nrow(data_select))
set.seed(123)
# particionamento aleatório
train_ind <- sample(seq_len(nrow(data_select)), size_sample)
# training x test
data_train <- data_select[train_ind, ]
data_test <- data_select[-train_ind, ]
# criando as tasks
train_task <- makeClassifTask(data = data_train, target = "classe")
test_task <- makeClassifTask(data = data_test, target = "classe")
# # normalizando as variáveis
train_task <- normalizeFeatures(train_task, method = "standardize" )
test_task <- normalizeFeatures(test_task, method = "standardize")
# removendo features
# train_task <- dropFeatures(task = train_task,features = c("grossura_pele"))
rf <- makeLearner("classif.randomForest", predict.type = "prob", par.vals = list(importance = TRUE))
getParamSet("classif.randomForest")
# gridsearch (parametros de tuning)
parameters <- makeParamSet(
makeIntegerParam("ntree",lower = 50, upper = 500),
makeIntegerParam("mtry", lower = 2, upper = 8),
makeIntegerParam("nodesize", lower = 5, upper = 50)
)
control_tune <- makeTuneControlRandom(maxit = 100L)
# cv
cv <- makeResampleDesc("CV",iters = 10L)
rf_tune <- tuneParams(learner = rf, resampling = cv, task = train_task, par.set = parameters, control = control_tune, show.info = TRUE)
# using hyperparameters
rf_tuning <- setHyperPars(rf, par.vals = rf_tune$x)
# configurando os parâmetros de tuning
rf <- mlr::train(rf_tuning, train_task)
getLearnerModel(rf)
# passando o conjunto de teste para o modelo
predict_rf<-predict(rf, test_task)
predict_rf
df <- data.frame(predict_rf$data)
# definindo a classe positiva como 1 (com diabetes)
# avaliar os resultados
library(caret)
confusionMatrix(df$response, df$truth, positive = levels(df$truth)[2])
# avaliando onde o modelo está errando
# df_error <- df[df$truth != df$response, ]
# df_error
#
# # selecionar as instâncias que o modelo errou
# data_select_error <- data_select[df_error$id,]
# data_select_error
beep()
roc.curve(df$truth, df$response, plotit = F)
getParamSet("classif.randomForest")
# teste local do modelo
# Etapa de criação do modelo
rm(list=ls())
# carga dos dados transformados
load("data/features_selection.RData")
head(data_select)
# library(ROSE)
# #
# # método de over e undersampling
# balanced_target <- ovun.sample(classe ~ ., data = data_select, method = "both",N = 680, seed = 1)$data
# data_select <- balanced_target
library(beepr)
library(mlr)
# tamanho dos dados para treino
size_sample <-  floor(0.7 * nrow(data_select))
set.seed(123)
# particionamento aleatório
train_ind <- sample(seq_len(nrow(data_select)), size_sample)
# training x test
data_train <- data_select[train_ind, ]
data_test <- data_select[-train_ind, ]
# criando as tasks
train_task <- makeClassifTask(data = data_train, target = "classe")
test_task <- makeClassifTask(data = data_test, target = "classe")
# # normalizando as variáveis
train_task <- normalizeFeatures(train_task, method = "standardize" )
test_task <- normalizeFeatures(test_task, method = "standardize")
# removendo features
# train_task <- dropFeatures(task = train_task,features = c("grossura_pele"))
rf <- makeLearner("classif.randomForest", predict.type = "prob", par.vals = list(mtry = 3, ntree = 200))
getParamSet("classif.randomForest")
rf$par.vals <- list(
importance = TRUE
)
# gridsearch (parametros de tuning)
parameters <- makeParamSet(
makeIntegerParam("ntree",lower = 50, upper = 500),
makeIntegerParam("mtry", lower = 2, upper = 8),
makeIntegerParam("nodesize", lower = 5, upper = 50)
)
control_tune <- makeTuneControlRandom(maxit = 100L)
# cv
cv <- makeResampleDesc("CV",iters = 10L)
rf_tune <- tuneParams(learner = rf, resampling = cv, task = train_task, par.set = parameters, control = control_tune, show.info = TRUE)
# using hyperparameters
rf_tuning <- setHyperPars(rf, par.vals = rf_tune$x)
# configurando os parâmetros de tuning
rf <- mlr::train(rf_tuning, train_task)
getLearnerModel(rf)
# passando o conjunto de teste para o modelo
predict_rf<-predict(rf, test_task)
predict_rf
df <- data.frame(predict_rf$data)
# definindo a classe positiva como 1 (com diabetes)
# avaliar os resultados
library(caret)
confusionMatrix(df$response, df$truth, positive = levels(df$truth)[2])
# avaliando onde o modelo está errando
# df_error <- df[df$truth != df$response, ]
# df_error
#
# # selecionar as instâncias que o modelo errou
# data_select_error <- data_select[df_error$id,]
# data_select_error
beep()
roc.curve(df$truth, df$response, plotit = F)
# teste local do modelo
# Etapa de criação do modelo
rm(list=ls())
# carga dos dados transformados
load("data/features_selection.RData")
head(data_select)
# library(ROSE)
# #
# # método de over e undersampling
# balanced_target <- ovun.sample(classe ~ ., data = data_select, method = "both",N = 680, seed = 1)$data
# data_select <- balanced_target
library(beepr)
library(mlr)
# tamanho dos dados para treino
size_sample <-  floor(0.7 * nrow(data_select))
set.seed(123)
# particionamento aleatório
train_ind <- sample(seq_len(nrow(data_select)), size_sample)
# training x test
data_train <- data_select[train_ind, ]
data_test <- data_select[-train_ind, ]
# criando as tasks
train_task <- makeClassifTask(data = data_train, target = "classe")
test_task <- makeClassifTask(data = data_test, target = "classe")
# # normalizando as variáveis
train_task <- normalizeFeatures(train_task, method = "standardize" )
test_task <- normalizeFeatures(test_task, method = "standardize")
# removendo features
# train_task <- dropFeatures(task = train_task,features = c("grossura_pele"))
rf <- makeLearner("classif.randomForest", predict.type = "prob", par.vals = list(mtry = 3, ntree = 100, importance = TRUE))
getParamSet("classif.randomForest")
# gridsearch (parametros de tuning)
parameters <- makeParamSet(
makeIntegerParam("ntree",lower = 50, upper = 500),
makeIntegerParam("mtry", lower = 2, upper = 8),
makeIntegerParam("nodesize", lower = 5, upper = 50)
)
control_tune <- makeTuneControlRandom(maxit = 100L)
# cv
cv <- makeResampleDesc("CV",iters = 10L)
rf_tune <- tuneParams(learner = rf, resampling = cv, task = train_task, par.set = parameters, control = control_tune, show.info = TRUE)
# using hyperparameters
rf_tuning <- setHyperPars(rf, par.vals = rf_tune$x)
# configurando os parâmetros de tuning
rf <- mlr::train(rf_tuning, train_task)
getLearnerModel(rf)
# passando o conjunto de teste para o modelo
predict_rf<-predict(rf, test_task)
predict_rf
df <- data.frame(predict_rf$data)
# definindo a classe positiva como 1 (com diabetes)
# avaliar os resultados
library(caret)
confusionMatrix(df$response, df$truth, positive = levels(df$truth)[2])
# avaliando onde o modelo está errando
# df_error <- df[df$truth != df$response, ]
# df_error
#
# # selecionar as instâncias que o modelo errou
# data_select_error <- data_select[df_error$id,]
# data_select_error
beep()
roc.curve(df$truth, df$response, plotit = F)
# teste local do modelo
# Etapa de criação do modelo
rm(list=ls())
# carga dos dados transformados
load("data/features_selection.RData")
head(data_select)
# library(ROSE)
# #
# # método de over e undersampling
# balanced_target <- ovun.sample(classe ~ ., data = data_select, method = "both",N = 680, seed = 1)$data
# data_select <- balanced_target
library(beepr)
library(mlr)
# tamanho dos dados para treino
size_sample <-  floor(0.7 * nrow(data_select))
set.seed(123)
# particionamento aleatório
train_ind <- sample(seq_len(nrow(data_select)), size_sample)
# training x test
data_train <- data_select[train_ind, ]
data_test <- data_select[-train_ind, ]
# criando as tasks
train_task <- makeClassifTask(data = data_train, target = "classe")
test_task <- makeClassifTask(data = data_test, target = "classe")
# # normalizando as variáveis
train_task <- normalizeFeatures(train_task, method = "standardize" )
test_task <- normalizeFeatures(test_task, method = "standardize")
# removendo features
# train_task <- dropFeatures(task = train_task,features = c("grossura_pele"))
rf <- makeLearner("classif.randomForest", predict.type = "prob", par.vals = list(mtry = 3, ntree = 100, importance = TRUE,
cutoff = c(0.6, 0.4)))
getParamSet("classif.randomForest")
# gridsearch (parametros de tuning)
parameters <- makeParamSet(
makeIntegerParam("ntree",lower = 50, upper = 500),
makeIntegerParam("mtry", lower = 2, upper = 8),
makeIntegerParam("nodesize", lower = 5, upper = 50)
)
control_tune <- makeTuneControlRandom(maxit = 100L)
# cv
cv <- makeResampleDesc("CV",iters = 10L)
rf_tune <- tuneParams(learner = rf, resampling = cv, task = train_task, par.set = parameters, control = control_tune, show.info = TRUE)
# using hyperparameters
rf_tuning <- setHyperPars(rf, par.vals = rf_tune$x)
# configurando os parâmetros de tuning
rf <- mlr::train(rf_tuning, train_task)
getLearnerModel(rf)
# passando o conjunto de teste para o modelo
predict_rf<-predict(rf, test_task)
predict_rf
df <- data.frame(predict_rf$data)
# definindo a classe positiva como 1 (com diabetes)
# avaliar os resultados
library(caret)
confusionMatrix(df$response, df$truth, positive = levels(df$truth)[2])
# avaliando onde o modelo está errando
# df_error <- df[df$truth != df$response, ]
# df_error
#
# # selecionar as instâncias que o modelo errou
# data_select_error <- data_select[df_error$id,]
# data_select_error
beep()
roc.curve(df$truth, df$response, plotit = F)
# teste local do modelo
# Etapa de criação do modelo
rm(list=ls())
# carga dos dados transformados
load("data/features_selection.RData")
head(data_select)
# library(ROSE)
# #
# # método de over e undersampling
# balanced_target <- ovun.sample(classe ~ ., data = data_select, method = "both",N = 680, seed = 1)$data
# data_select <- balanced_target
library(beepr)
library(mlr)
# tamanho dos dados para treino
size_sample <-  floor(0.7 * nrow(data_select))
set.seed(123)
# particionamento aleatório
train_ind <- sample(seq_len(nrow(data_select)), size_sample)
# training x test
data_train <- data_select[train_ind, ]
data_test <- data_select[-train_ind, ]
# criando as tasks
train_task <- makeClassifTask(data = data_train, target = "classe")
test_task <- makeClassifTask(data = data_test, target = "classe")
# # normalizando as variáveis
train_task <- normalizeFeatures(train_task, method = "standardize" )
test_task <- normalizeFeatures(test_task, method = "standardize")
# removendo features
# train_task <- dropFeatures(task = train_task,features = c("grossura_pele"))
rf <- makeLearner("classif.randomForest", predict.type = "prob", par.vals = list(mtry = 3, ntree = 200, importance = TRUE,
cutoff = c(0.4, 0.6)))
getParamSet("classif.randomForest")
# gridsearch (parametros de tuning)
parameters <- makeParamSet(
makeIntegerParam("ntree",lower = 50, upper = 500),
makeIntegerParam("mtry", lower = 2, upper = 8),
makeIntegerParam("nodesize", lower = 5, upper = 50)
)
control_tune <- makeTuneControlRandom(maxit = 100L)
# cv
cv <- makeResampleDesc("CV",iters = 10L)
rf_tune <- tuneParams(learner = rf, resampling = cv, task = train_task, par.set = parameters, control = control_tune, show.info = TRUE)
# using hyperparameters
rf_tuning <- setHyperPars(rf, par.vals = rf_tune$x)
# configurando os parâmetros de tuning
rf <- mlr::train(rf_tuning, train_task)
getLearnerModel(rf)
# passando o conjunto de teste para o modelo
predict_rf<-predict(rf, test_task)
predict_rf
df <- data.frame(predict_rf$data)
# definindo a classe positiva como 1 (com diabetes)
# avaliar os resultados
library(caret)
confusionMatrix(df$response, df$truth, positive = levels(df$truth)[2])
# avaliando onde o modelo está errando
# df_error <- df[df$truth != df$response, ]
# df_error
#
# # selecionar as instâncias que o modelo errou
# data_select_error <- data_select[df_error$id,]
# data_select_error
beep()
roc.curve(df$truth, df$response, plotit = F)
# teste local do modelo
# Etapa de criação do modelo
rm(list=ls())
# carga dos dados transformados
load("data/features_selection.RData")
head(data_select)
# library(ROSE)
# #
# # método de over e undersampling
# balanced_target <- ovun.sample(classe ~ ., data = data_select, method = "both",N = 680, seed = 1)$data
# data_select <- balanced_target
library(beepr)
library(mlr)
# tamanho dos dados para treino
size_sample <-  floor(0.7 * nrow(data_select))
set.seed(123)
# particionamento aleatório
train_ind <- sample(seq_len(nrow(data_select)), size_sample)
# training x test
data_train <- data_select[train_ind, ]
data_test <- data_select[-train_ind, ]
# criando as tasks
train_task <- makeClassifTask(data = data_train, target = "classe")
test_task <- makeClassifTask(data = data_test, target = "classe")
# # normalizando as variáveis
train_task <- normalizeFeatures(train_task, method = "standardize" )
test_task <- normalizeFeatures(test_task, method = "standardize")
# removendo features
# train_task <- dropFeatures(task = train_task,features = c("grossura_pele"))
rf <- makeLearner("classif.randomForest", predict.type = "prob", par.vals = list(mtry = 3, ntree = 200, importance = TRUE))
getParamSet("classif.randomForest")
# gridsearch (parametros de tuning)
parameters <- makeParamSet(
makeIntegerParam("ntree",lower = 50, upper = 500),
makeIntegerParam("mtry", lower = 2, upper = 8),
makeIntegerParam("nodesize", lower = 5, upper = 50)
)
control_tune <- makeTuneControlRandom(maxit = 100L)
# cv
cv <- makeResampleDesc("CV",iters = 10L)
rf_tune <- tuneParams(learner = rf, resampling = cv, task = train_task, par.set = parameters, control = control_tune, show.info = TRUE)
# using hyperparameters
rf_tuning <- setHyperPars(rf, par.vals = rf_tune$x)
# configurando os parâmetros de tuning
rf <- mlr::train(rf_tuning, train_task)
getLearnerModel(rf)
# passando o conjunto de teste para o modelo
predict_rf<-predict(rf, test_task)
predict_rf
df <- data.frame(predict_rf$data)
# definindo a classe positiva como 1 (com diabetes)
# avaliar os resultados
library(caret)
confusionMatrix(df$response, df$truth, positive = levels(df$truth)[2])
# avaliando onde o modelo está errando
# df_error <- df[df$truth != df$response, ]
# df_error
#
# # selecionar as instâncias que o modelo errou
# data_select_error <- data_select[df_error$id,]
# data_select_error
beep()
roc.curve(df$truth, df$response, plotit = F)
